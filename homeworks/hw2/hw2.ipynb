{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "VOCAB_SIZE = 50000\n",
    "NUM_CLASSES = 3\n",
    "NUM_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n",
    "NUM_DIRECTIONS = 2 if BIDIRECTIONAL else 1\n",
    "EMB_HIDDEN_SIZE, CLASS_HIDDEN_SIZE = 256, 512\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-4\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/snli_train.tsv', sep='\\t')\n",
    "val_data = pd.read_csv('data/snli_val.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'train': train_data,\n",
    "    'val': val_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young girl in a pink shirt sitting on a dock...</td>\n",
       "      <td>A young girl watching the sunset over the water .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman is smiling while the man next to her i...</td>\n",
       "      <td>Two people are next to each other .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Across the river , you can see a large building .</td>\n",
       "      <td>The large building is full of apartments and t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man in white shorts and a black shirt is par...</td>\n",
       "      <td>A man is riding a jetski on the ocean .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Four black dogs run together on bright green g...</td>\n",
       "      <td>Four dogs are preparing to be launched into sp...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A young girl in a pink shirt sitting on a dock...   \n",
       "1  A woman is smiling while the man next to her i...   \n",
       "2  Across the river , you can see a large building .   \n",
       "3  a man in white shorts and a black shirt is par...   \n",
       "4  Four black dogs run together on bright green g...   \n",
       "\n",
       "                                           sentence2          label  \n",
       "0  A young girl watching the sunset over the water .        neutral  \n",
       "1                Two people are next to each other .     entailment  \n",
       "2  The large building is full of apartments and t...        neutral  \n",
       "3            A man is riding a jetski on the ocean .  contradiction  \n",
       "4  Four dogs are preparing to be launched into sp...  contradiction  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young girl in a pink shirt sitting on a dock...</td>\n",
       "      <td>A young girl watching the sunset over the water .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman is smiling while the man next to her i...</td>\n",
       "      <td>Two people are next to each other .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Across the river , you can see a large building .</td>\n",
       "      <td>The large building is full of apartments and t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man in white shorts and a black shirt is par...</td>\n",
       "      <td>A man is riding a jetski on the ocean .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Four black dogs run together on bright green g...</td>\n",
       "      <td>Four dogs are preparing to be launched into sp...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A young girl in a pink shirt sitting on a dock...   \n",
       "1  A woman is smiling while the man next to her i...   \n",
       "2  Across the river , you can see a large building .   \n",
       "3  a man in white shorts and a black shirt is par...   \n",
       "4  Four black dogs run together on bright green g...   \n",
       "\n",
       "                                           sentence2          label  \n",
       "0  A young girl watching the sunset over the water .        neutral  \n",
       "1                Two people are next to each other .     entailment  \n",
       "2  The large building is full of apartments and t...        neutral  \n",
       "3            A man is riding a jetski on the ocean .  contradiction  \n",
       "4  Four dogs are preparing to be launched into sp...  contradiction  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    data['label'] = data['label'].map({'contradiction': 0, 'neutral': 1, 'entailment': 2})\n",
    "    data['sentence1'] = data['sentence1'].str.split()\n",
    "    data['sentence2'] = data['sentence2'].str.split()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(f_name, vocabulary):\n",
    "    f_in = io.open(f_name, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, f_in.readline().split())\n",
    "    vectors = {}\n",
    "    for line in f_in:\n",
    "        tokens = line.strip().split(' ')\n",
    "        if tokens[0] in vocabulary:\n",
    "            vectors[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(train_data, vocab_size):\n",
    "    '''\n",
    "    Returns:\n",
    "    id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    '''\n",
    "    print('Building vocabulary... ', end='', flush=True)\n",
    "    all_tokens = []\n",
    "    for row in (train_data['sentence1']+train_data['sentence2']).iteritems():\n",
    "        all_tokens += row[1]\n",
    "    vocabulary, count = zip(*Counter(all_tokens).most_common(vocab_size))\n",
    "    print('Done.')\n",
    "    print('Loading vectors... ', end='', flush=True)\n",
    "    vectors = load_vectors('data/wiki-news-300d-1M.vec', vocabulary)\n",
    "    vocabulary = [word for word in vocabulary if word in vectors]\n",
    "    print('Done.')\n",
    "    id2token = list(vocabulary)\n",
    "    token2id = dict(zip(vocabulary, range(2, 2+len(vocabulary))))\n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX\n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token, vectors\n",
    "\n",
    "def read_and_preprocess_data(data_dict, dataset, vocab_size=50000):\n",
    "    data = prepare_data(data_dict[dataset])\n",
    "    if dataset == 'train':\n",
    "        token2id, id2token, vectors = build_vocabulary(data, vocab_size)\n",
    "        return data, token2id, id2token, vectors\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, token2id, id2token, vectors = read_and_preprocess_data(data_dict, 'train', VOCAB_SIZE)\n",
    "# val_data = read_and_preprocess_data(data_dict, 'val')\n",
    "\n",
    "# pickle.dump(vectors, open('data/vectors.pkl', 'wb'))\n",
    "# pickle.dump(token2id, open('data/token2id.pkl', 'wb'))\n",
    "# pickle.dump(id2token, open('data/id2token.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_data(train_data)\n",
    "val_data = prepare_data(val_data)\n",
    "vectors = pickle.load(open('data/vectors.pkl', 'rb'))\n",
    "id2token = pickle.load(open('data/id2token.pkl', 'rb'))\n",
    "token2id = pickle.load(open('data/token2id.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22059"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id: 14732; Token: burping\n",
      "Token: burping; Token id: 14732\n"
     ]
    }
   ],
   "source": [
    "# Check the dictionary by loading random token from it\n",
    "random_token_id = np.random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "print(\"Token id: {}; Token: {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print(\"Token: {}; Token id: {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sentence_length(train_data, q=0.95):\n",
    "    max_sent1_len = train_data['sentence1'].str.len().quantile(q)\n",
    "    max_sent2_len = train_data['sentence2'].str.len().quantile(q)\n",
    "    return int(max(max_sent1_len, max_sent2_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = get_max_sentence_length(train_data)\n",
    "MAX_SENT_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, token2id):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.x1, self.x2, self.y = data['sentence1'].values, data['sentence2'].values, data['label'].values\n",
    "        assert (len(self.x1) == len(self.x2) == len(self.y))\n",
    "        self.token2id = token2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, row):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        label = self.y[row]\n",
    "        x1_word_idx, x2_word_idx = [], []\n",
    "        x1_mask, x2_mask = [], []\n",
    "        \n",
    "        for word in self.x1[row][:MAX_SENT_LENGTH]:\n",
    "            if word in self.token2id.keys():\n",
    "                x1_word_idx.append(self.token2id[word])\n",
    "                x1_mask.append(0)\n",
    "            else:\n",
    "                x1_word_idx.append(UNK_IDX)\n",
    "                x1_mask.append(1)\n",
    "                \n",
    "        for word in self.x2[row][:MAX_SENT_LENGTH]:\n",
    "            if word in self.token2id.keys():\n",
    "                x2_word_idx.append(self.token2id[word])\n",
    "                x2_mask.append(0)\n",
    "            else:\n",
    "                x2_word_idx.append(UNK_IDX)\n",
    "                x2_mask.append(1)\n",
    "        \n",
    "        x1_list = [x1_word_idx, x1_mask, len(x1_word_idx)]\n",
    "        x2_list = [x2_word_idx, x2_mask, len(x2_word_idx)]\n",
    "        return x1_list + x2_list + [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snli_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    x1_data, x2_data = [], []\n",
    "    x1_mask, x2_mask = [], []\n",
    "    x1_lengths, x2_lengths = [], []\n",
    "    labels = []\n",
    "\n",
    "    for datum in batch:\n",
    "        x1_lengths.append(datum[2])\n",
    "        x2_lengths.append(datum[5])\n",
    "        labels.append(datum[6])\n",
    "        \n",
    "        # Padding\n",
    "        x1_data_padded = np.pad(np.array(datum[0]), pad_width=((0, MAX_SENT_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        x1_data.append(x1_data_padded)\n",
    "        \n",
    "        x1_mask_padded = np.pad(np.array(datum[1]), pad_width=((0, MAX_SENT_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        x1_mask.append(x1_mask_padded)\n",
    "        \n",
    "        x2_data_padded = np.pad(np.array(datum[3]), pad_width=((0, MAX_SENT_LENGTH-datum[5])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        x2_data.append(x2_data_padded)\n",
    "        \n",
    "        x2_mask_padded = np.pad(np.array(datum[4]), pad_width=((0, MAX_SENT_LENGTH-datum[5])),\n",
    "                               mode=\"constant\", constant_values=0)\n",
    "        x2_mask.append(x2_mask_padded)\n",
    "        \n",
    "    ind_dec_order = np.argsort(x1_lengths)[::-1]\n",
    "    \n",
    "    x1_data = np.array(x1_data)[ind_dec_order]\n",
    "    x2_data = np.array(x2_data)[ind_dec_order]\n",
    "    \n",
    "    x1_mask = np.array(x1_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    x2_mask = np.array(x2_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    \n",
    "    x1_lengths = np.array(x1_lengths)[ind_dec_order]\n",
    "    x2_lengths = np.array(x2_lengths)[ind_dec_order]\n",
    "    \n",
    "    labels = np.array(labels)[ind_dec_order]\n",
    "    \n",
    "    x1_list = [torch.from_numpy(x1_data), torch.from_numpy(x1_mask).float(), x1_lengths]\n",
    "    x2_list = [torch.from_numpy(x2_data), torch.from_numpy(x2_mask).float(), x2_lengths]\n",
    "        \n",
    "    return x1_list + x2_list + [torch.from_numpy(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train, valid and test dataloaders\n",
    "\n",
    "train_dataset = SNLIDataset(train_data, token2id)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          collate_fn=snli_collate_func,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_dataset = SNLIDataset(val_data, token2id)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=snli_collate_func,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, emb_weights, vocab_size, bidirectional=False):\n",
    "        '''\n",
    "        params:\n",
    "            hidden_size: hidden Size of layer in GRU\n",
    "            num_layers: number of layers in GRU\n",
    "            output_size: dimension of output\n",
    "            vocab_size: vocabulary size\n",
    "            bidirectional: use bidirectional GRU\n",
    "        '''\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        \n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, 300, padding_idx=PAD_IDX)\n",
    "        self.gru = nn.GRU(300, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(emb_weights))\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        true2sorted = sorted(range(len(lengths)), key=lambda x: -lengths[x])\n",
    "        sorted2true = sorted(range(len(lengths)), key=lambda x: true2sorted[x])\n",
    "        x = x[true2sorted]\n",
    "        mask = mask[true2sorted]\n",
    "        lengths = lengths[true2sorted]\n",
    "        \n",
    "        batch_size, seq_len = x.size()\n",
    "        \n",
    "        # reset hidden state\n",
    "        self.hidden = self._init_hidden(batch_size)\n",
    "        \n",
    "        # get embedding of words\n",
    "        embed = self.embedding(x)\n",
    "        \n",
    "        # mask out all embeddings other than <unk> token to freeze their weights\n",
    "        embed = mask*embed + (1-mask)*embed.clone().detach()\n",
    "        \n",
    "        # pack padded sequence\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, lengths, batch_first=True)\n",
    "        \n",
    "        # forward prop though GRU\n",
    "        gru_out, self.hidden = self.gru(embed, self.hidden)\n",
    "        \n",
    "        # undo packing\n",
    "        gru_out, _ = torch.nn.utils.rnn.pad_packed_sequence(gru_out, batch_first=True)\n",
    "        \n",
    "        # (batch_size, seq_len, num_directions*hidden_size) -> (batch_size, seq_len, num_directions, hidden_size)\n",
    "        gru_out = gru_out.view(batch_size, -1, self.num_directions, self.hidden_size)\n",
    "        \n",
    "        # sum hidden activations of GRU across time\n",
    "        gru_out = torch.sum(gru_out, dim=1)\n",
    "        \n",
    "        # concat all directions along the hidden dimension\n",
    "        gru_out = torch.cat([gru_out[:,i,:] for i in range(self.num_directions)], dim=1)\n",
    "        \n",
    "        # get data back in original order of batches\n",
    "        gru_out = gru_out[sorted2true]\n",
    "        \n",
    "        return gru_out\n",
    "    \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_directions*self.num_layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes=3, num_directions=1, mode='cat'):\n",
    "        super(ClassificationNetwork, self).__init__()\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        # Fully connected and ReLU layers\n",
    "        if mode == 'cat':\n",
    "            self.fc1 = nn.Linear(2*input_size*num_directions, hidden_size)\n",
    "        elif mode in ['elementwise_mult', 'sum']:\n",
    "            self.fc1 = nn.Linear(input_size*num_directions, hidden_size)\n",
    "        else:\n",
    "            raise ValueError('Invalid arugment \"{}\" for mode!'.format(mode))\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, embedding_output1, embedding_output2):\n",
    "        if self.mode == 'cat':\n",
    "            input = torch.cat([embedding_output1, embedding_output2], dim=1)\n",
    "        elif self.mode == 'elementwise_mult':\n",
    "            input = embedding_output1 * embedding_output2\n",
    "        elif self.mode == 'sum':\n",
    "            input = embedding_output1 + embedding_output2\n",
    "        \n",
    "        input = input.view(input.size(0), -1) # Reshape input to batch_size x num_inputs\n",
    "        output = self.fc1(input)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc2(output)\n",
    "        return output\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.uniform_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights matrix\n",
    "def init_embedding_weights(vectors, token2id, id2token):\n",
    "    weights = np.zeros((len(token2id), 300))\n",
    "    for idx in range(2, len(vectors)):\n",
    "        weights[idx] = np.array(vectors[id2token[idx]])\n",
    "    np.random.seed(1337)\n",
    "    weights[1] = np.random.randn(300)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(embedding_network, classification_network, dataloader, criterion, optimizer, epoch):\n",
    "    embedding_network.train()\n",
    "    classification_network.train()\n",
    "    \n",
    "    loss_train = 0.\n",
    "    \n",
    "    for batch_idx, (x1, x1_mask, x1_lengths, x2, x2_mask, x2_lengths, y) in enumerate(dataloader):\n",
    "        x1, x1_mask, x2, x2_mask, y = x1.to(DEVICE), x1_mask.to(DEVICE), x2.to(DEVICE), x2_mask.to(DEVICE), y.to(DEVICE)\n",
    "        \n",
    "        embedding_network.train()\n",
    "        classification_network.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embedding_output1 = embedding_network(x1, x1_mask, x1_lengths)\n",
    "        embedding_output2 = embedding_network(x2, x2_mask, x2_lengths)\n",
    "        classification_output = classification_network(embedding_output1, embedding_output2)\n",
    "        \n",
    "        # Compute loss, back-prop, and take step\n",
    "        loss = criterion(classification_output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accurately compute loss, because of different batch size\n",
    "        loss_train += loss.item() * len(x1) / len(dataloader.dataset)\n",
    "\n",
    "        if (batch_idx+1) % (len(dataloader.dataset)//(10*y.shape[0])) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * y.shape[0], len(dataloader.dataset),\n",
    "                100. * (batch_idx+1) / len(dataloader), loss.item()))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(embedding_network, classification_network, dataloader, criterion):\n",
    "    embedding_network.eval()\n",
    "    classification_network.eval()\n",
    "    \n",
    "    loss_test = 0.\n",
    "    y_ls = []\n",
    "    output_ls = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x1, x1_mask, x1_lengths, x2, x2_mask, x2_lengths, y) in enumerate(dataloader):\n",
    "            x1, x1_mask, x2, x2_mask, y = x1.to(DEVICE), x1_mask.to(DEVICE), x2.to(DEVICE), x2_mask.to(DEVICE), y.to(DEVICE)\n",
    "            \n",
    "            embedding_output1 = embedding_network(x1, x1_mask, x1_lengths)\n",
    "            embedding_output2 = embedding_network(x2, x2_mask, x2_lengths)\n",
    "            classification_output = classification_network(embedding_output1, embedding_output2)\n",
    "            \n",
    "            loss = criterion(classification_output, y)\n",
    "\n",
    "            # Accurately compute loss, because of different batch size\n",
    "            loss_test += loss.item() / len(dataloader.dataset)\n",
    "\n",
    "            output_ls.append(classification_output)\n",
    "            y_ls.append(y)\n",
    "    return loss_test, torch.cat(output_ls, dim=0), torch.cat(y_ls, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(embedding_network, classification_network, dataloader, criterion):\n",
    "    _, y_predicted, y_true = test(\n",
    "        embedding_network=embedding_network,\n",
    "        classification_network=classification_network,\n",
    "        dataloader=dataloader,\n",
    "        criterion=criterion\n",
    "    )\n",
    "\n",
    "    y_predicted = y_predicted.max(1)[1]\n",
    "    return 100*y_predicted.eq(y_true.data.view_as(y_predicted)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_loader, val_loader, embedding_network, classification_network, criterion_train, criterion_test, optimizer):\n",
    "    train_loss_history, train_accuracy_history = [], []\n",
    "    val_loss_history, val_accuracy_history = [], []\n",
    "    stop_epoch = N_EPOCHS\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS+1):\n",
    "        try:\n",
    "            train_loss = train(\n",
    "                embedding_network=embedding_network,\n",
    "                classification_network=classification_network,\n",
    "                criterion=criterion_train,\n",
    "                dataloader=train_loader,\n",
    "                optimizer=optimizer,\n",
    "                epoch=epoch\n",
    "            )\n",
    "\n",
    "            val_loss, val_pred, val_true = test(\n",
    "                embedding_network=embedding_network,\n",
    "                classification_network=classification_network,\n",
    "                dataloader=val_loader,\n",
    "                criterion=criterion_test\n",
    "            )\n",
    "\n",
    "            accuracy_train = accuracy(embedding_network, classification_network, train_loader, criterion_test)\n",
    "            accuracy_val = accuracy(embedding_network, classification_network, val_loader, criterion_test)\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "            train_accuracy_history.append(accuracy_train)\n",
    "            val_accuracy_history.append(accuracy_val)\n",
    "\n",
    "            print('TRAIN Epoch: {}\\tAverage loss: {:.4f}, Accuracy: {:.0f}%'.format(epoch, train_loss, accuracy_train))\n",
    "            print('VAL   Epoch: {}\\tAverage loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(epoch, val_loss, accuracy_val))\n",
    "        except KeyboardInterrupt:\n",
    "            # Save the model checkpoints\n",
    "            print('Keyboard Interrupted!')\n",
    "            stop_epoch = epoch-1\n",
    "            break\n",
    "    \n",
    "    return embedding_network, classification_network, optimizer, train_loss_history, \\\n",
    "            val_loss_history, train_accuracy_history, val_accuracy_history, stop_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = init_embedding_weights(vectors, token2id, id2token)\n",
    "\n",
    "# Encoder and Classification Networks\n",
    "embedding_network_gru = GRUEncoder(hidden_size=EMB_HIDDEN_SIZE, num_layers=NUM_LAYERS, emb_weights=WEIGHTS, vocab_size=len(token2id), bidirectional=BIDIRECTIONAL).to(DEVICE)\n",
    "classification_network_gru = ClassificationNetwork(EMB_HIDDEN_SIZE, CLASS_HIDDEN_SIZE, NUM_CLASSES, NUM_DIRECTIONS).to(DEVICE)\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "criterion_test = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer_gru = torch.optim.Adam(list(embedding_network_gru.parameters())+list(classification_network_gru.parameters()), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [9984/100000 (10%)]\tLoss: 1.036453\n",
      "Train Epoch: 1 [19968/100000 (20%)]\tLoss: 1.020683\n",
      "Train Epoch: 1 [29952/100000 (30%)]\tLoss: 1.042392\n",
      "Train Epoch: 1 [39936/100000 (40%)]\tLoss: 1.119557\n",
      "Train Epoch: 1 [49920/100000 (50%)]\tLoss: 1.061677\n",
      "Train Epoch: 1 [59904/100000 (60%)]\tLoss: 1.025813\n",
      "Train Epoch: 1 [69888/100000 (70%)]\tLoss: 1.058093\n",
      "Train Epoch: 1 [79872/100000 (80%)]\tLoss: 0.989946\n",
      "Train Epoch: 1 [89856/100000 (90%)]\tLoss: 1.114789\n",
      "Train Epoch: 1 [99840/100000 (100%)]\tLoss: 1.054854\n",
      "TRAIN Epoch: 1\tAverage loss: 1.1065, Accuracy: 52%\n",
      "VAL   Epoch: 1\tAverage loss: 1.0007, Accuracy: 49%\n",
      "\n",
      "Train Epoch: 2 [9984/100000 (10%)]\tLoss: 0.858191\n",
      "Train Epoch: 2 [19968/100000 (20%)]\tLoss: 0.990322\n",
      "Train Epoch: 2 [29952/100000 (30%)]\tLoss: 0.922997\n",
      "Train Epoch: 2 [39936/100000 (40%)]\tLoss: 0.885996\n",
      "Train Epoch: 2 [49920/100000 (50%)]\tLoss: 0.944486\n",
      "Train Epoch: 2 [59904/100000 (60%)]\tLoss: 0.951894\n",
      "Train Epoch: 2 [69888/100000 (70%)]\tLoss: 0.912588\n",
      "Train Epoch: 2 [79872/100000 (80%)]\tLoss: 0.898441\n",
      "Train Epoch: 2 [89856/100000 (90%)]\tLoss: 1.039339\n",
      "Train Epoch: 2 [99840/100000 (100%)]\tLoss: 1.134440\n",
      "TRAIN Epoch: 2\tAverage loss: 0.9546, Accuracy: 58%\n",
      "VAL   Epoch: 2\tAverage loss: 0.9275, Accuracy: 56%\n",
      "\n",
      "Train Epoch: 3 [9984/100000 (10%)]\tLoss: 0.937780\n",
      "Train Epoch: 3 [19968/100000 (20%)]\tLoss: 1.004785\n",
      "Train Epoch: 3 [29952/100000 (30%)]\tLoss: 0.956013\n",
      "Train Epoch: 3 [39936/100000 (40%)]\tLoss: 0.802432\n",
      "Train Epoch: 3 [49920/100000 (50%)]\tLoss: 0.805488\n",
      "Train Epoch: 3 [59904/100000 (60%)]\tLoss: 0.975113\n",
      "Train Epoch: 3 [69888/100000 (70%)]\tLoss: 0.893720\n",
      "Train Epoch: 3 [79872/100000 (80%)]\tLoss: 0.878305\n",
      "Train Epoch: 3 [89856/100000 (90%)]\tLoss: 1.035426\n",
      "Train Epoch: 3 [99840/100000 (100%)]\tLoss: 0.926567\n",
      "TRAIN Epoch: 3\tAverage loss: 0.8951, Accuracy: 60%\n",
      "VAL   Epoch: 3\tAverage loss: 0.8737, Accuracy: 59%\n",
      "\n",
      "Train Epoch: 4 [9984/100000 (10%)]\tLoss: 0.714938\n",
      "Train Epoch: 4 [19968/100000 (20%)]\tLoss: 0.869316\n",
      "Train Epoch: 4 [29952/100000 (30%)]\tLoss: 0.902781\n",
      "Train Epoch: 4 [39936/100000 (40%)]\tLoss: 0.722499\n",
      "Train Epoch: 4 [49920/100000 (50%)]\tLoss: 0.772484\n",
      "Train Epoch: 4 [59904/100000 (60%)]\tLoss: 0.989548\n",
      "Train Epoch: 4 [69888/100000 (70%)]\tLoss: 0.986324\n",
      "Train Epoch: 4 [79872/100000 (80%)]\tLoss: 0.988268\n",
      "Train Epoch: 4 [89856/100000 (90%)]\tLoss: 0.858659\n",
      "Train Epoch: 4 [99840/100000 (100%)]\tLoss: 0.799307\n",
      "TRAIN Epoch: 4\tAverage loss: 0.8620, Accuracy: 63%\n",
      "VAL   Epoch: 4\tAverage loss: 0.8325, Accuracy: 63%\n",
      "\n",
      "Train Epoch: 5 [9984/100000 (10%)]\tLoss: 0.624798\n",
      "Train Epoch: 5 [19968/100000 (20%)]\tLoss: 0.951793\n",
      "Train Epoch: 5 [29952/100000 (30%)]\tLoss: 0.868173\n",
      "Train Epoch: 5 [39936/100000 (40%)]\tLoss: 0.685672\n",
      "Train Epoch: 5 [49920/100000 (50%)]\tLoss: 0.687507\n",
      "Train Epoch: 5 [59904/100000 (60%)]\tLoss: 0.981159\n",
      "Train Epoch: 5 [69888/100000 (70%)]\tLoss: 0.962358\n",
      "Train Epoch: 5 [79872/100000 (80%)]\tLoss: 0.879661\n",
      "Train Epoch: 5 [89856/100000 (90%)]\tLoss: 0.776237\n",
      "Train Epoch: 5 [99840/100000 (100%)]\tLoss: 0.916433\n",
      "TRAIN Epoch: 5\tAverage loss: 0.8307, Accuracy: 65%\n",
      "VAL   Epoch: 5\tAverage loss: 0.8180, Accuracy: 64%\n",
      "\n",
      "Train Epoch: 6 [9984/100000 (10%)]\tLoss: 0.819604\n",
      "Train Epoch: 6 [19968/100000 (20%)]\tLoss: 0.835531\n",
      "Train Epoch: 6 [29952/100000 (30%)]\tLoss: 0.842773\n",
      "Train Epoch: 6 [39936/100000 (40%)]\tLoss: 0.816828\n",
      "Train Epoch: 6 [49920/100000 (50%)]\tLoss: 0.771980\n",
      "Train Epoch: 6 [59904/100000 (60%)]\tLoss: 0.706370\n",
      "Train Epoch: 6 [69888/100000 (70%)]\tLoss: 0.698000\n",
      "Train Epoch: 6 [79872/100000 (80%)]\tLoss: 0.624918\n",
      "Train Epoch: 6 [89856/100000 (90%)]\tLoss: 1.060173\n",
      "Train Epoch: 6 [99840/100000 (100%)]\tLoss: 0.851154\n",
      "TRAIN Epoch: 6\tAverage loss: 0.8027, Accuracy: 67%\n",
      "VAL   Epoch: 6\tAverage loss: 0.7881, Accuracy: 67%\n",
      "\n",
      "Train Epoch: 7 [9984/100000 (10%)]\tLoss: 0.622669\n",
      "Train Epoch: 7 [19968/100000 (20%)]\tLoss: 0.836298\n",
      "Train Epoch: 7 [29952/100000 (30%)]\tLoss: 0.782525\n",
      "Train Epoch: 7 [39936/100000 (40%)]\tLoss: 0.965592\n",
      "Train Epoch: 7 [49920/100000 (50%)]\tLoss: 0.816038\n",
      "Train Epoch: 7 [59904/100000 (60%)]\tLoss: 0.747822\n",
      "Train Epoch: 7 [69888/100000 (70%)]\tLoss: 0.790101\n",
      "Train Epoch: 7 [79872/100000 (80%)]\tLoss: 0.867071\n",
      "Train Epoch: 7 [89856/100000 (90%)]\tLoss: 0.911335\n",
      "Train Epoch: 7 [99840/100000 (100%)]\tLoss: 0.961307\n",
      "TRAIN Epoch: 7\tAverage loss: 0.7801, Accuracy: 69%\n",
      "VAL   Epoch: 7\tAverage loss: 0.7569, Accuracy: 69%\n",
      "\n",
      "Train Epoch: 8 [9984/100000 (10%)]\tLoss: 0.575270\n",
      "Train Epoch: 8 [19968/100000 (20%)]\tLoss: 0.695887\n",
      "Train Epoch: 8 [29952/100000 (30%)]\tLoss: 0.732194\n",
      "Train Epoch: 8 [39936/100000 (40%)]\tLoss: 0.638108\n",
      "Train Epoch: 8 [49920/100000 (50%)]\tLoss: 0.848249\n",
      "Train Epoch: 8 [59904/100000 (60%)]\tLoss: 0.576744\n",
      "Train Epoch: 8 [69888/100000 (70%)]\tLoss: 0.781753\n",
      "Train Epoch: 8 [79872/100000 (80%)]\tLoss: 0.594771\n",
      "Train Epoch: 8 [89856/100000 (90%)]\tLoss: 0.483725\n",
      "Train Epoch: 8 [99840/100000 (100%)]\tLoss: 0.948738\n",
      "TRAIN Epoch: 8\tAverage loss: 0.7551, Accuracy: 70%\n",
      "VAL   Epoch: 8\tAverage loss: 0.7424, Accuracy: 69%\n",
      "\n",
      "Train Epoch: 9 [9984/100000 (10%)]\tLoss: 0.596983\n",
      "Train Epoch: 9 [19968/100000 (20%)]\tLoss: 0.722561\n",
      "Train Epoch: 9 [29952/100000 (30%)]\tLoss: 0.776175\n",
      "Train Epoch: 9 [39936/100000 (40%)]\tLoss: 0.569260\n",
      "Train Epoch: 9 [49920/100000 (50%)]\tLoss: 0.735894\n",
      "Train Epoch: 9 [59904/100000 (60%)]\tLoss: 0.935091\n",
      "Train Epoch: 9 [69888/100000 (70%)]\tLoss: 0.835087\n",
      "Train Epoch: 9 [79872/100000 (80%)]\tLoss: 0.628464\n",
      "Train Epoch: 9 [89856/100000 (90%)]\tLoss: 0.663585\n",
      "Train Epoch: 9 [99840/100000 (100%)]\tLoss: 0.758045\n",
      "TRAIN Epoch: 9\tAverage loss: 0.7360, Accuracy: 71%\n",
      "VAL   Epoch: 9\tAverage loss: 0.7232, Accuracy: 69%\n",
      "\n",
      "Train Epoch: 10 [9984/100000 (10%)]\tLoss: 0.496123\n",
      "Train Epoch: 10 [19968/100000 (20%)]\tLoss: 0.658408\n",
      "Train Epoch: 10 [29952/100000 (30%)]\tLoss: 0.746397\n",
      "Train Epoch: 10 [39936/100000 (40%)]\tLoss: 0.717854\n",
      "Train Epoch: 10 [49920/100000 (50%)]\tLoss: 0.731649\n",
      "Train Epoch: 10 [59904/100000 (60%)]\tLoss: 0.528325\n",
      "Train Epoch: 10 [69888/100000 (70%)]\tLoss: 0.801823\n",
      "Train Epoch: 10 [79872/100000 (80%)]\tLoss: 0.637013\n",
      "Train Epoch: 10 [89856/100000 (90%)]\tLoss: 0.798101\n",
      "Train Epoch: 10 [99840/100000 (100%)]\tLoss: 0.683638\n",
      "TRAIN Epoch: 10\tAverage loss: 0.7162, Accuracy: 72%\n",
      "VAL   Epoch: 10\tAverage loss: 0.7218, Accuracy: 71%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_network_gru, classification_network_gru, optimizer_gru, train_loss_history_gru, val_loss_history_gru, \\\n",
    "    train_accuracy_history_gru, val_accuracy_history_gru, stop_epoch_gru = \\\n",
    "    run_training(train_loader, val_loader, embedding_network_gru, classification_network_gru, \\\n",
    "                 criterion_train, criterion_test, optimizer_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, emb_weights):\n",
    "\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, 300, padding_idx=PAD_IDX)\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(300, hidden_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(emb_weights))\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        batch_size, seq_len = x.size()\n",
    "        \n",
    "        embed = self.embedding(x)\n",
    "        \n",
    "        hidden = self.conv1(embed.transpose(1,2)).transpose(1,2)\n",
    "        hidden = self.relu(hidden.contiguous().view(-1, hidden.size(-1)))\n",
    "        hidden = hidden.view(batch_size, seq_len, hidden.size(-1))\n",
    "        \n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = self.relu(hidden.contiguous().view(-1, hidden.size(-1)))\n",
    "        hidden = hidden.view(batch_size, seq_len, hidden.size(-1))\n",
    "        \n",
    "        out = torch.sum(hidden, dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = init_embedding_weights(vectors, token2id, id2token)\n",
    "\n",
    "# Encoder and Classification Networks\n",
    "embedding_network_cnn = CNNEncoder(hidden_size=EMB_HIDDEN_SIZE, vocab_size=len(token2id), emb_weights=WEIGHTS).to(DEVICE)\n",
    "classification_network_cnn = ClassificationNetwork(EMB_HIDDEN_SIZE, CLASS_HIDDEN_SIZE, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "criterion_test = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer_cnn = torch.optim.Adam(list(embedding_network_cnn.parameters())+list(classification_network_cnn.parameters()), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_network_cnn, classification_network_cnn, optimizer_cnn, train_loss_history_cnn, val_loss_history_cnn, \\\n",
    "    train_accuracy_history_cnn, val_accuracy_history_cnn, stop_epoch_cnns = \\\n",
    "    run_training(train_loader, val_loader, embedding_network_cnn, classification_network_cnn, \\\n",
    "                 criterion_train, criterion_test, optimizer_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:capstone_project]",
   "language": "python",
   "name": "conda-env-capstone_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
